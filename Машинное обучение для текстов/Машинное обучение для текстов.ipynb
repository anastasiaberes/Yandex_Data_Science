{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'>Привет, Артем! Спасибо за замечания и рекомендации. Постаралась все исправить.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-3)\" data-toc-modified-id=\"Общее-впечатление-(ревью-3)-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 3)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import notebook\n",
    "import warnings\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "toxic_comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "toxic_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8.841344371679229"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим сколько у нас токсичных/нектоксичных текстов\n",
    "display(toxic_comments['toxic'].value_counts())\n",
    "#Выведем соотношение\n",
    "class_ratio = toxic_comments['toxic'].value_counts()[0] / toxic_comments['toxic'].value_counts()[1]\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод\n",
    "\n",
    "Видим что классы несбалансированы, применем несколько способов балансировки и сравним их\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляю столбец Unnamed:\n",
    "toxic_comments = toxic_comments.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ввожу функцию очищения текстов постов:\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 s, sys: 35.1 ms, total: 3.58 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#очищаю тексты постов:\n",
    "toxic_comments['text'] = toxic_comments['text'].apply(clear_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ввожу функцию РОS-тэгирования слов:\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,               #прилагательное\n",
    "                \"N\": wordnet.NOUN,              #существительное\n",
    "                \"V\": wordnet.VERB,              #глагол\n",
    "                \"R\": wordnet.ADV                #наречие\n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#ввожу функцию леммализации тектов постов:\n",
    "def lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 51s, sys: 1min 26s, total: 16min 18s\n",
      "Wall time: 16min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#леммализирую тексты постов:\n",
    "toxic_comments['text'] = toxic_comments['text'].apply(lemm_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "type(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79646, 1)\n",
      "(39823, 1)\n",
      "(39823, 1)\n"
     ]
    }
   ],
   "source": [
    "# Разобьем выборку по отношению 50/20/20. Уменьшим количество кроссвалидаций до 3 из-за размера выборки.\n",
    "target = toxic_comments['toxic']\n",
    "features = toxic_comments.drop(['toxic'], axis=1)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, \n",
    "                                                                              target, \n",
    "                                                                              test_size=0.5, \n",
    "                                                                              random_state=1515)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, \n",
    "                                                                            target_valid, \n",
    "                                                                            test_size=0.5,\n",
    "                                                                            random_state=1515)\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "#count_tf_idf = TfidfVectorizer(stop_words=list(STOP_WORDS))\n",
    "\n",
    "#features_train = count_tf_idf.fit_transform(features_train['lemm_text'].values.astype('U'))\n",
    "#features_valid = count_tf_idf.transform(features_valid['lemm_text'].values.astype('U'))\n",
    "#features_test = count_tf_idf.transform(features_test['lemm_text'].values.astype('U'))\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)\n",
    "cv_counts = 2 #ввожу функцию очищения текстов постов:\n",
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля значений 1 в тренировочной выборке: 0.10129824473294327\n"
     ]
    }
   ],
   "source": [
    "#смотрю соотношение 1/0 в выборках на примере target_train:\n",
    "indices_1 = [i for i,x in enumerate(target_train) if x == 1]\n",
    "count_1 = len(indices_1)\n",
    "\n",
    "indices_0 = [i for i,x in enumerate(target_train) if x == 0]\n",
    "count_0 = len(indices_0)\n",
    "\n",
    "print('Доля значений 1 в тренировочной выборке:', len(indices_1) / (len(indices_1) + len(indices_0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ресемплинг с уменшением класса 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Соотношение 1/0 в тренировочной выборке:\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: toxic, dtype: float64\n",
      "\n",
      "(16136,)\n",
      "(16136,)\n",
      "CPU times: user 26.4 ms, sys: 4.23 ms, total: 30.7 ms\n",
      "Wall time: 29.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#уменьшаю кол-во 0 в выборках train:\n",
    "\n",
    "comments_train = toxic_comments.iloc[target_train.index]\n",
    "target_train_0 = comments_train[comments_train['toxic'] == 0]['toxic']\n",
    "target_train_1 = comments_train[comments_train['toxic'] == 1]['toxic']\n",
    "\n",
    "\n",
    "target_train_0_resample = target_train_0.sample(target_train_1.shape[0], random_state=12345)\n",
    "target_train_resample = pd.concat([target_train_0_resample, target_train_1])\n",
    "\n",
    "features_train_resample = toxic_comments.iloc[target_train_resample.index]\n",
    "\n",
    "features_train_resample, target_train_resample = shuffle(features_train_resample,\n",
    "                                                         target_train_resample,\n",
    "                                                         random_state=12345)\n",
    "\n",
    "features_train_resample = features_train_resample.text \n",
    "\n",
    "print('Соотношение 1/0 в тренировочной выборке:')\n",
    "print(target_train_resample.value_counts(normalize=True))\n",
    "print()\n",
    "print(features_train_resample.shape)\n",
    "print(target_train_resample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод\n",
    "\n",
    "В ходе подготовки данных мы получили признаки для обучения, получили обучающую, валидационную и тестовую выборку.\n",
    "\n",
    "Очистила тексты комментариев от ненужных знаков, леммализировала, убрала стоп-слова\n",
    "\n",
    "Сбалансировала данные в целевом признаке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 логистической регрессии = 0.76\n",
      "при параметрах {'lr__C': 5, 'lr__class_weight': 'balanced', 'lr__max_iter': 200, 'lr__random_state': 12345, 'lr__solver': 'lbfgs'}\n",
      "\n",
      "F1 логистической регрессии на валидации = 0.75\n",
      "\n",
      "Качество модели на кросс-валидации 0.755329790108115\n",
      "CPU times: user 7min 37s, sys: 5min 29s, total: 13min 7s\n",
      "Wall time: 13min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} #ну я поставила, хотя он тут не нужен\n",
    "                                                  #я ж сама сбалансировала их\n",
    "                                                  #нужен на несбалансированных данных, но у меня не получается их подать в модель\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "\n",
    "print('F1 логистической регрессии =', round(lr_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "lr_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 логистической регрессии на валидации =', round(lr_valid_f1,2))\n",
    "print()\n",
    "#кросc-валидация\n",
    "lrbs=gscv.best_score_\n",
    "print('Качество модели на кросс-валидации', lrbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 дерева решений = 0.63\n",
      "при параметрах {'dtc__class_weight': 'balanced', 'dtc__max_depth': 23, 'dtc__random_state': 12345}\n",
      "\n",
      "F1 дерева решений на валидации = 0.63\n",
      "\n",
      "Качество модели на кросс-валидации 0.6334738586784482\n",
      "CPU times: user 6min 35s, sys: 765 ms, total: 6min 35s\n",
      "Wall time: 6min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"dtc\", DecisionTreeClassifier())])\n",
    "    \n",
    "parameters = {'dtc__max_depth': ([x for x in range(1, 25)]),\n",
    "              'dtc__random_state': ([12345]), \n",
    "              'dtc__class_weight': (['balanced'])}\n",
    "\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "dtc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 дерева решений =', round(dtc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "dtc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 дерева решений на валидации =', round(dtc_valid_f1,2))\n",
    "print()\n",
    "#кросc-валидация\n",
    "dtbs=gscv.best_score_\n",
    "print('Качество модели на кросс-валидации', dtbs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 CatBoostClassifier = 0.73\n",
      "при параметрах {'cbc__class_weights': (1, 1), 'cbc__iterations': 200, 'cbc__verbose': False}\n",
      "\n",
      "F1 CatBoostClassifier на валидации = 0.73\n",
      "\n",
      "Качество модели на кросс-валидации 0.7283102965329712\n",
      "CPU times: user 23min 56s, sys: 13 s, total: 24min 8s\n",
      "Wall time: 24min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english')), \n",
    "                     (\"cbc\", CatBoostClassifier())])\n",
    "    \n",
    "parameters = {'cbc__verbose': ([False]),\n",
    "              'cbc__iterations': ([200]),\n",
    "              'cbc__class_weights':([(1, 1), (1, 11)])} \n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "cbc_train_f1 = max(mts)\n",
    "\n",
    "print('F1 CatBoostClassifier =', round(cbc_train_f1,2))\n",
    "print('при параметрах', gscv.best_params_)\n",
    "print()\n",
    "\n",
    "#валидация:\n",
    "predictions_valid = gscv.predict(features_valid.text)\n",
    "cbc_valid_f1 = f1_score(target_valid, predictions_valid)\n",
    "print('F1 CatBoostClassifier на валидации =', round(cbc_valid_f1,2))\n",
    "print()\n",
    "#кросc-валидация\n",
    "cbs=gscv.best_score_\n",
    "print('Качество модели на кросс-валидации', cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели BERT можно посмотреть по ссылке https://colab.research.google.com/drive/11ozHURPSOQlegktOhgULARLnlmSOeDYH?usp=sharing. Данная модель обеспечивает качество F1 - 0.69. Ее рекомендовать не будем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 на обучающей выборке</th>\n",
       "      <th>F1 на валидационной выборке</th>\n",
       "      <th>Качество модели на кросс-валидации</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.755330</td>\n",
       "      <td>0.753827</td>\n",
       "      <td>0.755330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.728310</td>\n",
       "      <td>0.727960</td>\n",
       "      <td>0.728310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.633474</td>\n",
       "      <td>0.633470</td>\n",
       "      <td>0.633474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F1 на обучающей выборке  F1 на валидационной выборке  \\\n",
       "LogisticRegression                     0.755330                     0.753827   \n",
       "CatBoostClassifier                     0.728310                     0.727960   \n",
       "DecisionTreeClassifier                 0.633474                     0.633470   \n",
       "\n",
       "                        Качество модели на кросс-валидации  \n",
       "LogisticRegression                                0.755330  \n",
       "CatBoostClassifier                                0.728310  \n",
       "DecisionTreeClassifier                            0.633474  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['LogisticRegression',\n",
    "         'DecisionTreeClassifier',\n",
    "         'CatBoostClassifier']\n",
    "\n",
    "data = {'F1 на обучающей выборке': [lr_train_f1,\n",
    "                                    dtc_train_f1,\n",
    "                                    cbc_train_f1],\n",
    "        \n",
    "        'F1 на валидационной выборке': [lr_valid_f1,\n",
    "                                        dtc_valid_f1,\n",
    "                                        cbc_valid_f1],\n",
    "        'Качество модели на кросс-валидации': [lrbs,\n",
    "                                        dtbs,\n",
    "                                        cbs],}\n",
    "f1_data = pd.DataFrame(data=data, index=index)\n",
    "\n",
    "f1_data.sort_values(by='Качество модели на кросс-валидации', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно проведенным расчетам моделей, лучше всего себя показала LogisticRegression. Проведем ее тестирование на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "финальный (тестовый) тестовый F1 логистической регрессии = 0.76\n"
     ]
    }
   ],
   "source": [
    "#тестирование:\n",
    "#обучение:\n",
    "pipeline = Pipeline([(\"vect\", TfidfVectorizer(stop_words='english', sublinear_tf=True)), \n",
    "                     (\"lr\", LogisticRegression())])\n",
    "    \n",
    "parameters = {'lr__solver': ('liblinear', 'saga','newton-cg', 'lbfgs'),\n",
    "              'lr__C': (.1, 1, 5, 10),\n",
    "              'lr__random_state': ([12345]),\n",
    "              'lr__max_iter': ([200]),\n",
    "              'lr__class_weight': (['balanced'])} #ну я поставила, хотя он тут не нужен\n",
    "                                                  #я ж сама сбалансировала их\n",
    "                                                  #нужен на несбалансированных данных, но у меня не получается их подать в модель\n",
    "gscv = GridSearchCV(pipeline, parameters, scoring='f1', cv=3, n_jobs=-1)\n",
    "\n",
    "gscv.fit(features_train, target_train)\n",
    "\n",
    "mts = gscv.cv_results_['mean_test_score']\n",
    "lr_train_f1 = max(mts)\n",
    "predictions_test = gscv.predict(features_test.text)\n",
    "lr_test_f1 = f1_score(target_test, predictions_test)\n",
    "print('финальный (тестовый) тестовый F1 логистической регрессии =', round(lr_test_f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовая выборка показала результат близкий с результатом на кросс-валидации. Можем рекомендовать данную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аутсайдером среди моделей стала DecisionTreeClassifier, так как дала наименьшее F1.Модель BERT дала 0,69\n",
    "\n",
    "Наилучшей моделью стала LogisticRegression, которая на тестировании показала F1 = 0.755. Поскольку требовалось найти модель классификации комментариев на позитивные и негативные со значением метрики качества F1 >= 0.75, рекомендовать могу LogisticRegression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 3609,
    "start_time": "2023-07-10T11:16:33.860Z"
   },
   {
    "duration": 171,
    "start_time": "2023-07-10T11:16:56.717Z"
   },
   {
    "duration": 2361,
    "start_time": "2023-07-10T11:17:24.767Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-10T11:17:54.066Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-10T11:18:14.424Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-10T11:19:01.531Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-10T11:19:22.781Z"
   },
   {
    "duration": 3909,
    "start_time": "2023-07-10T11:19:36.282Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-10T11:19:54.996Z"
   },
   {
    "duration": 1036917,
    "start_time": "2023-07-10T11:20:07.655Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-10T11:45:08.420Z"
   },
   {
    "duration": 35,
    "start_time": "2023-07-10T11:45:22.852Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-10T11:45:43.992Z"
   },
   {
    "duration": 32,
    "start_time": "2023-07-10T11:49:35.920Z"
   },
   {
    "duration": 46,
    "start_time": "2023-07-10T11:49:50.725Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-10T11:50:37.735Z"
   },
   {
    "duration": 117,
    "start_time": "2023-07-10T11:50:57.901Z"
   },
   {
    "duration": 57,
    "start_time": "2023-07-10T11:51:36.539Z"
   },
   {
    "duration": 1500473,
    "start_time": "2023-07-10T11:51:48.748Z"
   },
   {
    "duration": 106310,
    "start_time": "2023-07-10T12:16:49.223Z"
   },
   {
    "duration": 3405,
    "start_time": "2023-07-11T11:10:42.203Z"
   },
   {
    "duration": 2289,
    "start_time": "2023-07-11T11:10:45.610Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-11T11:10:47.900Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-11T11:10:47.912Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-11T11:10:47.926Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-11T11:10:47.936Z"
   },
   {
    "duration": 4192,
    "start_time": "2023-07-11T11:10:47.946Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-11T11:10:52.139Z"
   },
   {
    "duration": 1106060,
    "start_time": "2023-07-11T11:10:52.145Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-11T11:29:18.207Z"
   },
   {
    "duration": 47,
    "start_time": "2023-07-11T11:29:18.215Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-11T11:29:18.263Z"
   },
   {
    "duration": 47,
    "start_time": "2023-07-11T11:29:18.271Z"
   },
   {
    "duration": 55,
    "start_time": "2023-07-11T11:29:18.321Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-11T11:29:18.377Z"
   },
   {
    "duration": 913469,
    "start_time": "2023-07-11T11:29:18.382Z"
   },
   {
    "duration": 118873,
    "start_time": "2023-07-11T11:44:31.853Z"
   },
   {
    "duration": 566821,
    "start_time": "2023-07-11T11:46:30.727Z"
   },
   {
    "duration": 119,
    "start_time": "2023-07-11T11:55:57.550Z"
   },
   {
    "duration": 174705,
    "start_time": "2023-07-11T11:55:57.671Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-11T11:58:52.378Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T11:58:52.394Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T11:58:52.396Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T11:58:52.397Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T11:58:52.398Z"
   },
   {
    "duration": 2060,
    "start_time": "2023-07-11T12:00:35.618Z"
   },
   {
    "duration": 808,
    "start_time": "2023-07-11T12:00:37.680Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-11T12:00:38.490Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-11T12:00:38.502Z"
   },
   {
    "duration": 6932,
    "start_time": "2023-07-11T12:00:38.527Z"
   },
   {
    "duration": 2617,
    "start_time": "2023-07-11T12:00:45.461Z"
   },
   {
    "duration": 11814,
    "start_time": "2023-07-11T12:00:48.080Z"
   },
   {
    "duration": 55380,
    "start_time": "2023-07-11T12:00:59.896Z"
   },
   {
    "duration": 37607,
    "start_time": "2023-07-11T12:01:55.278Z"
   },
   {
    "duration": 41291,
    "start_time": "2023-07-11T12:02:32.888Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-11T12:03:14.181Z"
   },
   {
    "duration": 1045,
    "start_time": "2023-07-11T12:03:14.205Z"
   },
   {
    "duration": 22528,
    "start_time": "2023-07-11T12:03:15.252Z"
   },
   {
    "duration": 84014,
    "start_time": "2023-07-11T12:03:37.871Z"
   },
   {
    "duration": 11,
    "start_time": "2023-07-11T12:05:01.887Z"
   },
   {
    "duration": 292205,
    "start_time": "2023-07-11T12:05:01.899Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-11T12:09:54.105Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.110Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.111Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.112Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.114Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.115Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-11T12:09:54.116Z"
   },
   {
    "duration": 32742,
    "start_time": "2023-07-11T12:14:34.489Z"
   },
   {
    "duration": 685046,
    "start_time": "2023-07-11T12:15:07.233Z"
   },
   {
    "duration": 34568,
    "start_time": "2023-07-11T12:26:32.281Z"
   },
   {
    "duration": 491,
    "start_time": "2023-07-11T12:27:06.852Z"
   },
   {
    "duration": 89,
    "start_time": "2023-07-11T12:27:07.345Z"
   },
   {
    "duration": 90,
    "start_time": "2023-07-11T12:27:07.436Z"
   },
   {
    "duration": 325,
    "start_time": "2023-07-11T13:14:05.120Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-11T13:38:14.421Z"
   },
   {
    "duration": 1309,
    "start_time": "2023-07-11T13:38:49.956Z"
   },
   {
    "duration": 895313,
    "start_time": "2023-07-11T13:40:23.558Z"
   },
   {
    "duration": 397,
    "start_time": "2023-07-11T13:55:18.873Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-11T14:04:30.261Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-11T14:04:48.789Z"
   },
   {
    "duration": 2012,
    "start_time": "2023-07-11T19:02:12.514Z"
   },
   {
    "duration": 838,
    "start_time": "2023-07-11T19:02:14.528Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-11T19:02:15.368Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-11T19:02:15.385Z"
   },
   {
    "duration": 7413,
    "start_time": "2023-07-11T19:02:15.407Z"
   },
   {
    "duration": 2533,
    "start_time": "2023-07-11T19:02:22.821Z"
   },
   {
    "duration": 11477,
    "start_time": "2023-07-11T19:02:25.355Z"
   },
   {
    "duration": 59568,
    "start_time": "2023-07-11T19:02:36.833Z"
   },
   {
    "duration": 39477,
    "start_time": "2023-07-11T19:03:36.404Z"
   },
   {
    "duration": 41701,
    "start_time": "2023-07-11T19:04:15.884Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-11T19:04:57.586Z"
   },
   {
    "duration": 1128,
    "start_time": "2023-07-11T19:04:57.612Z"
   },
   {
    "duration": 25848,
    "start_time": "2023-07-11T19:04:58.742Z"
   },
   {
    "duration": 88182,
    "start_time": "2023-07-11T19:05:24.672Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-11T19:06:52.855Z"
   },
   {
    "duration": 321132,
    "start_time": "2023-07-11T19:06:52.874Z"
   },
   {
    "duration": 31605,
    "start_time": "2023-07-11T19:12:14.008Z"
   },
   {
    "duration": 688295,
    "start_time": "2023-07-11T19:12:45.614Z"
   },
   {
    "duration": 35629,
    "start_time": "2023-07-11T19:24:13.911Z"
   },
   {
    "duration": 923899,
    "start_time": "2023-07-11T19:24:49.542Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-11T19:40:13.443Z"
   },
   {
    "duration": 17210,
    "start_time": "2023-07-12T07:06:37.637Z"
   },
   {
    "duration": 3116,
    "start_time": "2023-07-12T07:09:31.398Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-12T07:09:36.276Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-12T07:11:38.123Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-12T07:11:40.686Z"
   },
   {
    "duration": 8561,
    "start_time": "2023-07-12T07:12:15.951Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-12T07:12:31.955Z"
   },
   {
    "duration": 325,
    "start_time": "2023-07-12T07:12:52.580Z"
   },
   {
    "duration": 2351,
    "start_time": "2023-07-12T07:13:07.759Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-12T07:15:30.642Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-12T07:15:38.379Z"
   },
   {
    "duration": 88,
    "start_time": "2023-07-12T07:15:50.991Z"
   },
   {
    "duration": 2208,
    "start_time": "2023-07-12T07:18:26.410Z"
   },
   {
    "duration": 919,
    "start_time": "2023-07-12T07:18:31.260Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-12T07:18:32.350Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-12T07:18:33.550Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-12T07:18:35.776Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-12T07:18:36.984Z"
   },
   {
    "duration": 4188,
    "start_time": "2023-07-12T07:18:49.973Z"
   },
   {
    "duration": 7,
    "start_time": "2023-07-12T07:18:57.405Z"
   },
   {
    "duration": 1313650,
    "start_time": "2023-07-12T07:19:02.141Z"
   },
   {
    "duration": 3370,
    "start_time": "2023-07-12T08:26:51.196Z"
   },
   {
    "duration": 70,
    "start_time": "2023-07-12T08:42:47.271Z"
   },
   {
    "duration": 41,
    "start_time": "2023-07-12T08:44:10.010Z"
   },
   {
    "duration": 49,
    "start_time": "2023-07-12T08:44:29.249Z"
   },
   {
    "duration": 38,
    "start_time": "2023-07-12T08:45:05.938Z"
   },
   {
    "duration": 45,
    "start_time": "2023-07-12T08:45:13.370Z"
   },
   {
    "duration": 42,
    "start_time": "2023-07-12T08:45:15.206Z"
   },
   {
    "duration": 370,
    "start_time": "2023-07-12T08:45:16.823Z"
   },
   {
    "duration": 107,
    "start_time": "2023-07-12T08:45:43.397Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-12T08:45:48.318Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-12T08:45:51.172Z"
   },
   {
    "duration": 208,
    "start_time": "2023-07-12T08:45:56.918Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-12T08:46:04.802Z"
   },
   {
    "duration": 425,
    "start_time": "2023-07-12T08:46:07.104Z"
   },
   {
    "duration": 80,
    "start_time": "2023-07-12T08:47:46.797Z"
   },
   {
    "duration": 54,
    "start_time": "2023-07-12T08:49:03.396Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-12T08:54:33.379Z"
   },
   {
    "duration": 137,
    "start_time": "2023-07-12T09:00:56.893Z"
   },
   {
    "duration": 42,
    "start_time": "2023-07-12T09:01:20.476Z"
   },
   {
    "duration": 196,
    "start_time": "2023-07-12T09:05:26.017Z"
   },
   {
    "duration": 349,
    "start_time": "2023-07-12T09:06:30.405Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-12T09:07:14.818Z"
   },
   {
    "duration": 2325,
    "start_time": "2023-07-12T09:22:36.672Z"
   },
   {
    "duration": 925,
    "start_time": "2023-07-12T09:22:39.000Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-12T09:22:39.928Z"
   },
   {
    "duration": 37,
    "start_time": "2023-07-12T09:22:39.958Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-12T09:22:39.997Z"
   },
   {
    "duration": 87,
    "start_time": "2023-07-12T09:22:40.021Z"
   },
   {
    "duration": 4896,
    "start_time": "2023-07-12T09:22:40.110Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-12T09:22:45.009Z"
   },
   {
    "duration": 1306267,
    "start_time": "2023-07-12T09:22:45.016Z"
   },
   {
    "duration": 3246,
    "start_time": "2023-07-12T09:44:31.286Z"
   },
   {
    "duration": 70,
    "start_time": "2023-07-12T09:44:34.533Z"
   },
   {
    "duration": 26,
    "start_time": "2023-07-12T09:44:34.604Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-12T09:44:34.632Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-12T09:44:34.663Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-12T09:44:34.674Z"
   },
   {
    "duration": 47,
    "start_time": "2023-07-12T09:44:34.691Z"
   },
   {
    "duration": 353,
    "start_time": "2023-07-12T09:44:34.740Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.095Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.096Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.098Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.100Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.101Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.103Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.104Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.105Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.107Z"
   },
   {
    "duration": 0,
    "start_time": "2023-07-12T09:44:35.109Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-12T09:52:33.984Z"
   },
   {
    "duration": 610,
    "start_time": "2023-07-12T09:52:37.352Z"
   },
   {
    "duration": 41,
    "start_time": "2023-07-12T09:52:59.595Z"
   },
   {
    "duration": 199,
    "start_time": "2023-07-12T09:53:03.837Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-12T09:53:11.194Z"
   },
   {
    "duration": 869571,
    "start_time": "2023-07-12T09:53:12.042Z"
   },
   {
    "duration": 79668,
    "start_time": "2023-07-12T10:29:34.292Z"
   },
   {
    "duration": 450892,
    "start_time": "2023-07-12T10:47:00.797Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-12T12:01:46.316Z"
   },
   {
    "duration": 38,
    "start_time": "2023-07-12T12:08:36.158Z"
   },
   {
    "duration": 65,
    "start_time": "2023-07-12T12:09:40.257Z"
   },
   {
    "duration": 38,
    "start_time": "2023-07-12T12:09:43.167Z"
   },
   {
    "duration": 4881,
    "start_time": "2023-07-12T19:19:35.905Z"
   },
   {
    "duration": 3417,
    "start_time": "2023-07-12T19:19:40.788Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-12T19:19:44.207Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-12T19:19:44.219Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-12T19:19:44.237Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-12T19:19:44.248Z"
   },
   {
    "duration": 4459,
    "start_time": "2023-07-12T19:19:44.259Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-12T19:19:48.720Z"
   },
   {
    "duration": 1207360,
    "start_time": "2023-07-12T19:19:48.726Z"
   },
   {
    "duration": 2742,
    "start_time": "2023-07-12T19:39:56.089Z"
   },
   {
    "duration": 61,
    "start_time": "2023-07-12T19:39:58.833Z"
   },
   {
    "duration": 24,
    "start_time": "2023-07-12T19:39:58.896Z"
   },
   {
    "duration": 56,
    "start_time": "2023-07-12T19:39:58.922Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-12T19:39:58.980Z"
   },
   {
    "duration": 953226,
    "start_time": "2023-07-12T19:39:58.984Z"
   },
   {
    "duration": 76654,
    "start_time": "2023-07-12T19:55:52.212Z"
   },
   {
    "duration": 391943,
    "start_time": "2023-07-12T19:57:08.868Z"
   },
   {
    "duration": 17,
    "start_time": "2023-07-12T20:03:40.813Z"
   },
   {
    "duration": 6424,
    "start_time": "2023-07-14T12:21:34.287Z"
   },
   {
    "duration": 2500,
    "start_time": "2023-07-14T12:21:40.713Z"
   },
   {
    "duration": 12,
    "start_time": "2023-07-14T12:21:43.215Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T12:21:43.230Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-14T12:21:43.247Z"
   },
   {
    "duration": 18,
    "start_time": "2023-07-14T12:21:43.264Z"
   },
   {
    "duration": 4222,
    "start_time": "2023-07-14T12:21:43.284Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T12:21:47.509Z"
   },
   {
    "duration": 1234136,
    "start_time": "2023-07-14T12:21:47.516Z"
   },
   {
    "duration": 2839,
    "start_time": "2023-07-14T12:42:21.654Z"
   },
   {
    "duration": 90,
    "start_time": "2023-07-14T12:42:24.495Z"
   },
   {
    "duration": 34,
    "start_time": "2023-07-14T12:42:24.587Z"
   },
   {
    "duration": 100,
    "start_time": "2023-07-14T12:42:24.623Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-14T12:42:24.725Z"
   },
   {
    "duration": 936565,
    "start_time": "2023-07-14T12:42:24.730Z"
   },
   {
    "duration": 536275,
    "start_time": "2023-07-14T12:58:01.297Z"
   },
   {
    "duration": 5162,
    "start_time": "2023-07-14T19:10:13.460Z"
   },
   {
    "duration": 2450,
    "start_time": "2023-07-14T19:10:18.624Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-14T19:10:21.076Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T19:10:21.087Z"
   },
   {
    "duration": 14,
    "start_time": "2023-07-14T19:10:21.105Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-14T19:10:21.121Z"
   },
   {
    "duration": 4004,
    "start_time": "2023-07-14T19:10:21.148Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-14T19:10:25.154Z"
   },
   {
    "duration": 1134930,
    "start_time": "2023-07-14T19:10:25.160Z"
   },
   {
    "duration": 2444,
    "start_time": "2023-07-14T19:29:20.092Z"
   },
   {
    "duration": 53,
    "start_time": "2023-07-14T19:29:22.537Z"
   },
   {
    "duration": 22,
    "start_time": "2023-07-14T19:29:22.592Z"
   },
   {
    "duration": 55,
    "start_time": "2023-07-14T19:29:22.616Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-14T19:29:22.675Z"
   },
   {
    "duration": 890406,
    "start_time": "2023-07-14T19:29:22.680Z"
   },
   {
    "duration": 467298,
    "start_time": "2023-07-14T19:44:13.088Z"
   },
   {
    "duration": 2064,
    "start_time": "2023-07-14T20:05:40.229Z"
   },
   {
    "duration": 915,
    "start_time": "2023-07-14T20:05:42.297Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-14T20:05:43.214Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-14T20:05:43.232Z"
   },
   {
    "duration": 31,
    "start_time": "2023-07-14T20:05:43.260Z"
   },
   {
    "duration": 16,
    "start_time": "2023-07-14T20:05:43.293Z"
   },
   {
    "duration": 4444,
    "start_time": "2023-07-14T20:05:43.311Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-14T20:05:47.757Z"
   },
   {
    "duration": 1776,
    "start_time": "2023-07-15T06:21:05.102Z"
   },
   {
    "duration": 772,
    "start_time": "2023-07-15T06:21:06.880Z"
   },
   {
    "duration": 10,
    "start_time": "2023-07-15T06:21:07.653Z"
   },
   {
    "duration": 9,
    "start_time": "2023-07-15T06:21:07.675Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-15T06:21:07.685Z"
   },
   {
    "duration": 2,
    "start_time": "2023-07-15T06:21:07.699Z"
   },
   {
    "duration": 3601,
    "start_time": "2023-07-15T06:21:07.702Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-15T06:21:11.305Z"
   },
   {
    "duration": 979346,
    "start_time": "2023-07-15T06:21:11.310Z"
   },
   {
    "duration": 2371,
    "start_time": "2023-07-15T06:37:30.659Z"
   },
   {
    "duration": 53,
    "start_time": "2023-07-15T06:37:33.032Z"
   },
   {
    "duration": 20,
    "start_time": "2023-07-15T06:37:33.087Z"
   },
   {
    "duration": 50,
    "start_time": "2023-07-15T06:37:33.108Z"
   },
   {
    "duration": 2,
    "start_time": "2023-07-15T06:37:33.160Z"
   },
   {
    "duration": 788568,
    "start_time": "2023-07-15T06:37:33.163Z"
   },
   {
    "duration": 396346,
    "start_time": "2023-07-15T06:50:41.733Z"
   },
   {
    "duration": 1456064,
    "start_time": "2023-07-15T06:57:18.080Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-15T07:21:34.146Z"
   },
   {
    "duration": 766964,
    "start_time": "2023-07-15T07:21:34.160Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
